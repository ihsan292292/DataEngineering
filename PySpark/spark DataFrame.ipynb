{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "645e3588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.8</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83fc3264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.8</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f0f02949b00>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de9bde7",
   "metadata": {},
   "source": [
    "1. ### create new spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1041163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93265fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "config = SparkConf().setAppName(\"PySparkSession\").setMaster(\"local[4]\")\n",
    "sc = SparkContext(conf=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753a5e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Session ()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('pySparkSession').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c7ece9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: `/flights': File exists\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -mkdir /flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dde2685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put: `/flights/raw_flight_data.csv': File exists\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -put /home/hadoop/Downloads/raw_flight_data.csv /flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31a4c13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_df = spark.read.csv('/flights/raw_flight_data.csv',inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31be4499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DayofMonth=19, DayOfWeek=5, Carrier='DL', OriginAirportID=11433, DestAirportID=13303, DepDelay=-3, ArrDelay=1),\n",
       " Row(DayofMonth=19, DayOfWeek=5, Carrier='DL', OriginAirportID=14869, DestAirportID=12478, DepDelay=0, ArrDelay=-8),\n",
       " Row(DayofMonth=19, DayOfWeek=5, Carrier='DL', OriginAirportID=14057, DestAirportID=14869, DepDelay=-4, ArrDelay=-15)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e85ddbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|Carrier|\n",
      "+-------+\n",
      "|     UA|\n",
      "|     AA|\n",
      "|     EV|\n",
      "|     B6|\n",
      "|     DL|\n",
      "|     OO|\n",
      "|     F9|\n",
      "|     YV|\n",
      "|     US|\n",
      "|     MQ|\n",
      "|     HA|\n",
      "|     AS|\n",
      "|     FL|\n",
      "|     VX|\n",
      "|     WN|\n",
      "|     9E|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df.select('Carrier').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5651e84f",
   "metadata": {},
   "source": [
    "###2.count - Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50dee964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_df.select('Carrier').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd711438",
   "metadata": {},
   "outputs": [],
   "source": [
    "###3.Where()- just like filter method of RDD with boolean conditions statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8ee2ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DayofMonth',\n",
       " 'DayOfWeek',\n",
       " 'Carrier',\n",
       " 'OriginAirportID',\n",
       " 'DestAirportID',\n",
       " 'DepDelay',\n",
       " 'ArrDelay']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d53f14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|        19|        5|     DL|          15016|        11433|      28|      24|\n",
      "|        19|        5|     DL|          10397|        14869|      15|      24|\n",
      "|        19|        5|     DL|          10397|        10423|      33|      34|\n",
      "|        19|        5|     DL|          11278|        10397|     323|     322|\n",
      "|        19|        5|     DL|          11433|        11298|      22|      41|\n",
      "|        19|        5|     DL|          11298|        11433|      40|      20|\n",
      "|        19|        5|     DL|          10397|        12451|      71|      75|\n",
      "|        19|        5|     DL|          12451|        10397|      75|      57|\n",
      "|        19|        5|     DL|          10397|        14771|      31|      38|\n",
      "|        19|        5|     DL|          13204|        10397|       8|      25|\n",
      "|        19|        5|     DL|          12889|        13487|       7|      16|\n",
      "|        19|        5|     DL|          14027|        10397|      13|      25|\n",
      "|        19|        5|     DL|          13244|        10397|       4|      13|\n",
      "|        19|        5|     DL|          10397|        12892|      15|       7|\n",
      "|        19|        5|     DL|          14747|        14869|      15|      18|\n",
      "|        19|        5|     DL|          10423|        10397|      56|      49|\n",
      "|        20|        6|     DL|          10397|        11278|       2|       1|\n",
      "|        20|        6|     DL|          11278|        10397|      34|      38|\n",
      "|        20|        6|     DL|          11697|        12953|      20|       1|\n",
      "|        20|        6|     DL|          13487|        13198|      35|      26|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df.where((flights_df.DepDelay>0)&(flights_df.ArrDelay>0)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5c041fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "815851"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_df.where((flights_df.DepDelay>0)&(flights_df.ArrDelay>0)).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a86efa5",
   "metadata": {},
   "source": [
    "### 4.Filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4cf08f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|        19|        5|     DL|          15016|        11433|      28|      24|\n",
      "|        19|        5|     DL|          10397|        14869|      15|      24|\n",
      "|        19|        5|     DL|          10397|        10423|      33|      34|\n",
      "|        19|        5|     DL|          11278|        10397|     323|     322|\n",
      "|        19|        5|     DL|          11433|        11298|      22|      41|\n",
      "|        19|        5|     DL|          11298|        11433|      40|      20|\n",
      "|        19|        5|     DL|          10397|        12451|      71|      75|\n",
      "|        19|        5|     DL|          12451|        10397|      75|      57|\n",
      "|        19|        5|     DL|          10397|        14771|      31|      38|\n",
      "|        19|        5|     DL|          13204|        10397|       8|      25|\n",
      "|        19|        5|     DL|          12889|        13487|       7|      16|\n",
      "|        19|        5|     DL|          14027|        10397|      13|      25|\n",
      "|        19|        5|     DL|          13244|        10397|       4|      13|\n",
      "|        19|        5|     DL|          10397|        12892|      15|       7|\n",
      "|        19|        5|     DL|          14747|        14869|      15|      18|\n",
      "|        19|        5|     DL|          10423|        10397|      56|      49|\n",
      "|        20|        6|     DL|          10397|        11278|       2|       1|\n",
      "|        20|        6|     DL|          11278|        10397|      34|      38|\n",
      "|        20|        6|     DL|          11697|        12953|      20|       1|\n",
      "|        20|        6|     DL|          13487|        13198|      35|      26|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df.filter((flights_df.DepDelay>0)&(flights_df.ArrDelay>0)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5293fa33",
   "metadata": {},
   "source": [
    "### 5.isin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4965eaa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d19a8c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|        19|        5|     DL|          11433|        13303|      -3|       1|\n",
      "|        19|        5|     DL|          14869|        12478|       0|      -8|\n",
      "|        19|        5|     DL|          14057|        14869|      -4|     -15|\n",
      "|        19|        5|     DL|          15016|        11433|      28|      24|\n",
      "|        19|        5|     DL|          11193|        12892|      -6|     -11|\n",
      "|        19|        5|     DL|          10397|        15016|      -1|     -19|\n",
      "|        19|        5|     DL|          15016|        10397|       0|      -1|\n",
      "|        19|        5|     DL|          10397|        14869|      15|      24|\n",
      "|        19|        5|     DL|          10397|        10423|      33|      34|\n",
      "|        19|        5|     DL|          11278|        10397|     323|     322|\n",
      "|        19|        5|     DL|          14107|        13487|      -7|     -13|\n",
      "|        19|        5|     DL|          11433|        11298|      22|      41|\n",
      "|        19|        5|     DL|          11298|        11433|      40|      20|\n",
      "|        19|        5|     DL|          11433|        12892|      -2|      -7|\n",
      "|        19|        5|     DL|          10397|        12451|      71|      75|\n",
      "|        19|        5|     DL|          12451|        10397|      75|      57|\n",
      "|        19|        5|     DL|          12953|        10397|      -1|      10|\n",
      "|        19|        5|     DL|          11433|        12953|      -3|     -10|\n",
      "|        19|        5|     DL|          10397|        14771|      31|      38|\n",
      "|        19|        5|     DL|          13204|        10397|       8|      25|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df.where(flights_df.Carrier.isin('DL','B6','UA')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea7d855",
   "metadata": {},
   "source": [
    "###################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eaa5ff",
   "metadata": {},
   "source": [
    "## Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db748317",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_df = spark.read.csv(\"file:///home/hadoop/Downloads/airports.csv\",header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84481da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----+--------------------+\n",
      "|airport_id|       city|state|                name|\n",
      "+----------+-----------+-----+--------------------+\n",
      "|     10165|Adak Island|   AK|                Adak|\n",
      "|     10299|  Anchorage|   AK|Ted Stevens Ancho...|\n",
      "|     10304|      Aniak|   AK|       Aniak Airport|\n",
      "|     10754|     Barrow|   AK|Wiley Post/Will R...|\n",
      "|     10551|     Bethel|   AK|      Bethel Airport|\n",
      "|     10926|    Cordova|   AK|Merle K Mudhole S...|\n",
      "|     14709|  Deadhorse|   AK|   Deadhorse Airport|\n",
      "|     11336| Dillingham|   AK|  Dillingham Airport|\n",
      "|     11630|  Fairbanks|   AK|Fairbanks Interna...|\n",
      "|     11997|   Gustavus|   AK|    Gustavus Airport|\n",
      "|     12523|     Juneau|   AK|Juneau International|\n",
      "|     12819|  Ketchikan|   AK|Ketchikan Interna...|\n",
      "|     10245|King Salmon|   AK| King Salmon Airport|\n",
      "|     10170|     Kodiak|   AK|      Kodiak Airport|\n",
      "|     13970|   Kotzebue|   AK| Ralph Wien Memorial|\n",
      "|     13873|       Nome|   AK|        Nome Airport|\n",
      "|     14256| Petersburg|   AK|Petersburg James ...|\n",
      "|     14828|      Sitka|   AK|Sitka Rocky Gutie...|\n",
      "|     12807| St. Mary's|   AK|  St. Mary's Airport|\n",
      "|     11445|   Unalaska|   AK|    Unalaska Airport|\n",
      "+----------+-----------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airports_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a322d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+--------------------+----------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|                name|airport_id|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+--------------------+----------+\n",
      "|        19|        5|     DL|          11433|        13303|      -3|       1|Detroit Metro Way...|     11433|\n",
      "|        19|        5|     DL|          14869|        12478|       0|      -8|Salt Lake City In...|     14869|\n",
      "|        19|        5|     DL|          14057|        14869|      -4|     -15|Portland Internat...|     14057|\n",
      "|        19|        5|     DL|          15016|        11433|      28|      24|Lambert-St. Louis...|     15016|\n",
      "|        19|        5|     DL|          11193|        12892|      -6|     -11|Cincinnati/Northe...|     11193|\n",
      "|        19|        5|     DL|          10397|        15016|      -1|     -19|Hartsfield-Jackso...|     10397|\n",
      "|        19|        5|     DL|          15016|        10397|       0|      -1|Lambert-St. Louis...|     15016|\n",
      "|        19|        5|     DL|          10397|        14869|      15|      24|Hartsfield-Jackso...|     10397|\n",
      "|        19|        5|     DL|          10397|        10423|      33|      34|Hartsfield-Jackso...|     10397|\n",
      "|        19|        5|     DL|          11278|        10397|     323|     322|Ronald Reagan Was...|     11278|\n",
      "|        19|        5|     DL|          14107|        13487|      -7|     -13|Phoenix Sky Harbo...|     14107|\n",
      "|        19|        5|     DL|          11433|        11298|      22|      41|Detroit Metro Way...|     11433|\n",
      "|        19|        5|     DL|          11298|        11433|      40|      20|Dallas/Fort Worth...|     11298|\n",
      "|        19|        5|     DL|          11433|        12892|      -2|      -7|Detroit Metro Way...|     11433|\n",
      "|        19|        5|     DL|          10397|        12451|      71|      75|Hartsfield-Jackso...|     10397|\n",
      "|        19|        5|     DL|          12451|        10397|      75|      57|Jacksonville Inte...|     12451|\n",
      "|        19|        5|     DL|          12953|        10397|      -1|      10|           LaGuardia|     12953|\n",
      "|        19|        5|     DL|          11433|        12953|      -3|     -10|Detroit Metro Way...|     11433|\n",
      "|        19|        5|     DL|          10397|        14771|      31|      38|Hartsfield-Jackso...|     10397|\n",
      "|        19|        5|     DL|          13204|        10397|       8|      25|Orlando Internati...|     13204|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "air_flight = flights_df.join(airports_df.select(['name','airport_id']), flights_df.OriginAirportID == airports_df.airport_id)\n",
    "\n",
    "air_flight.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff110ea8",
   "metadata": {},
   "source": [
    "### is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49660cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54dea799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|         0|        0|      0|              0|            0|   27444|   29033|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df.select([count(when(isnull(col),col)).alias(col) for col in flights_df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9998c7bf",
   "metadata": {},
   "source": [
    "### flights_df.toPandas() - Type casting spark DF to pandas DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "617b5e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_df1 = flights_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d807ea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perc(flights_df1,flights_df):\n",
    "    count1 = flights_df1.count()\n",
    "    count2 = flights_df.count()\n",
    "    res = (count2-count1)/count2*100\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83e2305d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8249927006440348"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc(flights_df1,flights_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403875a2",
   "metadata": {},
   "source": [
    "### 10.fillna() : \n",
    "    *to replace or fill missing columns with central tendancy (mean, median, mode)*\n",
    "        *Here will replace missing values by 0s*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3a23de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_null_df = air_flight.fillna(0,subset = ['DepDelay','ArrDelay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4e2a161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+--------------------+----------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|                name|airport_id|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+--------------------+----------+\n",
      "|        19|        5|     DL|          11433|        13303|      -3|       1|Detroit Metro Way...|     11433|\n",
      "|        19|        5|     DL|          14869|        12478|       0|      -8|Salt Lake City In...|     14869|\n",
      "|        19|        5|     DL|          14057|        14869|      -4|     -15|Portland Internat...|     14057|\n",
      "|        19|        5|     DL|          15016|        11433|      28|      24|Lambert-St. Louis...|     15016|\n",
      "|        19|        5|     DL|          11193|        12892|      -6|     -11|Cincinnati/Northe...|     11193|\n",
      "|        19|        5|     DL|          10397|        15016|      -1|     -19|Hartsfield-Jackso...|     10397|\n",
      "|        19|        5|     DL|          15016|        10397|       0|      -1|Lambert-St. Louis...|     15016|\n",
      "|        19|        5|     DL|          10397|        14869|      15|      24|Hartsfield-Jackso...|     10397|\n",
      "|        19|        5|     DL|          10397|        10423|      33|      34|Hartsfield-Jackso...|     10397|\n",
      "|        19|        5|     DL|          11278|        10397|     323|     322|Ronald Reagan Was...|     11278|\n",
      "|        19|        5|     DL|          14107|        13487|      -7|     -13|Phoenix Sky Harbo...|     14107|\n",
      "|        19|        5|     DL|          11433|        11298|      22|      41|Detroit Metro Way...|     11433|\n",
      "|        19|        5|     DL|          11298|        11433|      40|      20|Dallas/Fort Worth...|     11298|\n",
      "|        19|        5|     DL|          11433|        12892|      -2|      -7|Detroit Metro Way...|     11433|\n",
      "|        19|        5|     DL|          10397|        12451|      71|      75|Hartsfield-Jackso...|     10397|\n",
      "|        19|        5|     DL|          12451|        10397|      75|      57|Jacksonville Inte...|     12451|\n",
      "|        19|        5|     DL|          12953|        10397|      -1|      10|           LaGuardia|     12953|\n",
      "|        19|        5|     DL|          11433|        12953|      -3|     -10|Detroit Metro Way...|     11433|\n",
      "|        19|        5|     DL|          10397|        14771|      31|      38|Hartsfield-Jackso...|     10397|\n",
      "|        19|        5|     DL|          13204|        10397|       8|      25|Orlando Internati...|     13204|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fill_null_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a75b82e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|mean|\n",
      "+----+\n",
      "|11.0|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "air_flight.select(round(mean('DepDelay')).alias('mean')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fdc46e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|std_env|\n",
      "+-------+\n",
      "|   36.0|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import stddev\n",
    "flights_df.select(round(stddev('DepDelay')).alias('std_env')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79e258e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_df.select(round(stddev('DepDelay')).alias('std_env')).collect()[0]['std_env']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c065b033",
   "metadata": {},
   "source": [
    "### 11.GroupBy() and agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10e52b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.group.GroupedData at 0x7f0f01616898>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_df.groupBy(\"Carrier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc5ef385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|Carrier|     Average Delay|\n",
      "+-------+------------------+\n",
      "|     UA|12.583842334149837|\n",
      "|     AA|12.064006771147696|\n",
      "|     EV|14.489477751011318|\n",
      "|     B6| 12.62171906310568|\n",
      "|     DL| 7.362576157252043|\n",
      "|     OO| 7.882683537596901|\n",
      "|     F9|12.110275408919335|\n",
      "|     YV| 9.544919992288413|\n",
      "|     US| 4.944337992909899|\n",
      "|     MQ|15.538911606849465|\n",
      "|     HA|1.1510517278385919|\n",
      "|     AS|0.6253646218816666|\n",
      "|     FL|10.185264524505032|\n",
      "|     VX|14.352406955022273|\n",
      "|     WN|12.838167030213425|\n",
      "|     9E| 9.734131353219817|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df.groupBy(\"Carrier\").agg(mean(\"DepDelay\").alias(\"Average Delay\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "303257f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_df.approxQuantile('ArrDelay',[0.5],0.001)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60871831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99a86a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "median_expr = expr(f\"percentile_approx({'ArrDelay'},0.5)\")\n",
    "flights_df.agg(median_expr.alias(\"median\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a37f807",
   "metadata": {},
   "source": [
    "### 13.Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84d68007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE TEMPORARY TABLE USING SPARK DATA FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0242d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_df.createOrReplaceTempView(\"flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3680f9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|        19|        5|     DL|          11433|        13303|      -3|       1|\n",
      "|        19|        5|     DL|          14869|        12478|       0|      -8|\n",
      "|        19|        5|     DL|          14057|        14869|      -4|     -15|\n",
      "|        19|        5|     DL|          15016|        11433|      28|      24|\n",
      "|        19|        5|     DL|          11193|        12892|      -6|     -11|\n",
      "|        19|        5|     DL|          10397|        15016|      -1|     -19|\n",
      "|        19|        5|     DL|          15016|        10397|       0|      -1|\n",
      "|        19|        5|     DL|          10397|        14869|      15|      24|\n",
      "|        19|        5|     DL|          10397|        10423|      33|      34|\n",
      "|        19|        5|     DL|          11278|        10397|     323|     322|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from flights limit 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93bc055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the total number of flights of each carrier\n",
    "#compute median departure delay for each carrier\n",
    "#find the most busy airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "955bdd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|Carrier|count(Carrier)|\n",
      "+-------+--------------+\n",
      "|     WN|        580029|\n",
      "|     DL|        385040|\n",
      "|     AA|        291771|\n",
      "|     UA|        287601|\n",
      "|     US|        235031|\n",
      "|     OO|        161102|\n",
      "|     EV|        158253|\n",
      "|     B6|        122297|\n",
      "|     MQ|        113634|\n",
      "|     FL|         93013|\n",
      "|     9E|         80221|\n",
      "|     AS|         69056|\n",
      "|     YV|         53022|\n",
      "|     F9|         35821|\n",
      "|     VX|         34869|\n",
      "|     HA|         18658|\n",
      "+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select Carrier,count(Carrier) from flights group by Carrier order by count(Carrier) desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "770a3eb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o726.showString.\n: java.lang.UnsupportedOperationException: Cannot evaluate expression: count(distinct input[0, string, true])\n\tat org.apache.spark.sql.catalyst.expressions.Unevaluable$class.doGenCode(Expression.scala:261)\n\tat org.apache.spark.sql.catalyst.expressions.aggregate.AggregateExpression.doGenCode(interfaces.scala:87)\n\tat org.apache.spark.sql.catalyst.expressions.Expression$$anonfun$genCode$2.apply(Expression.scala:108)\n\tat org.apache.spark.sql.catalyst.expressions.Expression$$anonfun$genCode$2.apply(Expression.scala:105)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.sql.catalyst.expressions.Expression.genCode(Expression.scala:105)\n\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateOrdering$$anonfun$3.apply(GenerateOrdering.scala:83)\n\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateOrdering$$anonfun$3.apply(GenerateOrdering.scala:82)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateOrdering$.genComparisons(GenerateOrdering.scala:82)\n\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateOrdering$.create(GenerateOrdering.scala:164)\n\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateOrdering$.create(GenerateOrdering.scala:43)\n\tat org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator.generate(CodeGenerator.scala:1193)\n\tat org.apache.spark.sql.catalyst.expressions.codegen.LazilyGeneratedOrdering.<init>(GenerateOrdering.scala:207)\n\tat org.apache.spark.sql.catalyst.expressions.codegen.LazilyGeneratedOrdering.<init>(GenerateOrdering.scala:204)\n\tat org.apache.spark.sql.execution.TakeOrderedAndProjectExec.executeCollect(limit.scala:135)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3388)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3369)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3368)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2764)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.GeneratedMethodAccessor106.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-dd1a306757a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"select Carrier from flights order by count(distinct Carrier) desc limit 1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \"\"\"\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o726.showString.\n: java.lang.UnsupportedOperationException: Cannot evaluate expression: count(distinct input[0, string, true])\n\tat org.apache.spark.sql.catalyst.expressions.Unevaluable$class.doGenCode(Expression.scala:261)\n\tat org.apache.spark.sql.catalyst.expressions.aggregate.AggregateExpression.doGenCode(interfaces.scala:87)\n\tat org.apache.spark.sql.catalyst.expressions.Expression$$anonfun$genCode$2.apply(Expression.scala:108)\n\tat org.apache.spark.sql.catalyst.expressions.Expression$$anonfun$genCode$2.apply(Expression.scala:105)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.sql.catalyst.expressions.Expression.genCode(Expression.scala:105)\n\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateOrdering$$anonfun$3.apply(GenerateOrdering.scala:83)\n\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateOrdering$$anonfun$3.apply(GenerateOrdering.scala:82)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateOrdering$.genComparisons(GenerateOrdering.scala:82)\n\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateOrdering$.create(GenerateOrdering.scala:164)\n\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateOrdering$.create(GenerateOrdering.scala:43)\n\tat org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator.generate(CodeGenerator.scala:1193)\n\tat org.apache.spark.sql.catalyst.expressions.codegen.LazilyGeneratedOrdering.<init>(GenerateOrdering.scala:207)\n\tat org.apache.spark.sql.catalyst.expressions.codegen.LazilyGeneratedOrdering.<init>(GenerateOrdering.scala:204)\n\tat org.apache.spark.sql.execution.TakeOrderedAndProjectExec.executeCollect(limit.scala:135)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3388)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3369)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3368)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2764)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.GeneratedMethodAccessor106.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select Carrier where max(count(distinct OriginAirportID) )(select )count(distinct OriginAirportID)  from flights\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f6696434",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseException",
     "evalue": "\"\\nno viable alternative at input 'GROUP ('(line 1, pos 41)\\n\\n== SQL ==\\nSELECT PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY DepDelay) AS median FROM flights\\n-----------------------------------------^^^\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o65.sql.\n: org.apache.spark.sql.catalyst.parser.ParseException: \nno viable alternative at input 'GROUP ('(line 1, pos 41)\n\n== SQL ==\nSELECT PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY DepDelay) AS median FROM flights\n-----------------------------------------^^^\n\n\tat org.apache.spark.sql.catalyst.parser.ParseException.withCommand(ParseDriver.scala:241)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parse(ParseDriver.scala:117)\n\tat org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:48)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(ParseDriver.scala:69)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:643)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mParseException\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-745be786ff3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY DepDelay) AS median FROM flights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \"\"\"\n\u001b[0;32m--> 767\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.parser.ParseException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mParseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.streaming.StreamingQueryException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStreamingQueryException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mParseException\u001b[0m: \"\\nno viable alternative at input 'GROUP ('(line 1, pos 41)\\n\\n== SQL ==\\nSELECT PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY DepDelay) AS median FROM flights\\n-----------------------------------------^^^\\n\""
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT carrier, percentile_approx(DepDepart)(0.5) WITHIN GROUP (ORDER BY your_column) AS median FROM \n",
    "    your_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75619322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
